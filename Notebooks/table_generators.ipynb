{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import ast\n",
    "from collections import deque, defaultdict\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "from Simulators_and_Solvers.cube_simulator_for_table_generators import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_move_table():\n",
    "    \"\"\"\n",
    "    Generates a table mapping each move to the positions it affects and their new positions.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where keys are move names and values are dictionaries\n",
    "              mapping initial positions to final positions after the move.\n",
    "    \"\"\"\n",
    "    # Create a fresh Cube object\n",
    "    cube = Cube()\n",
    "    movement_table = {}\n",
    "\n",
    "    tracked_positions = [(i,j,k) for i in range(0,3) for j in range(0,3) for k in range(0,3)]\n",
    "\n",
    "    movement_table = defaultdict(dict)\n",
    "    for move in cube.move_map.keys():\n",
    "        # Get a fresh cube for each move calculation\n",
    "        test_cube = Cube()\n",
    "\n",
    "        # Apply the move\n",
    "        test_cube.apply_moves(move)\n",
    "        for initial_pos in tracked_positions:\n",
    "            piece_id_to_track = test_cube.piece_initial_ids_at_positions[initial_pos]\n",
    "            final_pos = test_cube.get_position_of_piece(piece_id_to_track) # Find where that piece ended up\n",
    "            movement_table[move][initial_pos] = final_pos\n",
    "\n",
    "        del test_cube\n",
    "\n",
    "    # Save to file\n",
    "    with open('../Precomputed_Tables/position_movement_table.json', 'w') as f:\n",
    "        # Convert tuple positions to strings for JSON serialization\n",
    "        serializable_table = {}\n",
    "        for move, position_movements in movement_table.items():\n",
    "            serializable_movements = {}\n",
    "            for from_pos, to_pos in position_movements.items():\n",
    "                from_pos_str = str(from_pos)\n",
    "                to_pos_str = str(to_pos)\n",
    "                serializable_movements[from_pos_str] = to_pos_str\n",
    "            serializable_table[move] = serializable_movements\n",
    "\n",
    "        json.dump(serializable_table, f, indent=2)\n",
    "    \n",
    "    #Acknowledge successful table creation\n",
    "    print(\"Created the table Successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created the table Successfully\n"
     ]
    }
   ],
   "source": [
    "generate_move_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_distance_table(piece_type:str, filename:str):\n",
    "    \"\"\"\n",
    "    Calculates the minimum distances (ignoring the piece orientations and the rest of the cube) between each pair of the pieces of the given piece type, using Breadth-First Search (BFS)\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the position_movement_table created in the previous cell:\n",
    "    try:\n",
    "        filename_1 = \"../Precomputed_Tables/position_movement_table.json\"\n",
    "        with open(filename_1, 'r') as f:\n",
    "            serializable_table:dict = json.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load {filename_1}: {e}\")\n",
    "\n",
    "    # Serialize the loaded position_movement json table with the structure -\n",
    "    # {position(tuple): {move(str): new_position(tuple)}}\n",
    "    movement_table = defaultdict(dict)\n",
    "    for move, position_movements in serializable_table.items():\n",
    "        for from_pos_str, to_pos_str in position_movements.items():\n",
    "            from_pos = tuple(ast.literal_eval(from_pos_str))\n",
    "            to_pos = tuple(ast.literal_eval(to_pos_str))\n",
    "            movement_table[from_pos][move] = to_pos\n",
    "\n",
    "    solved_cube = Cube()\n",
    "    all_moves = list(solved_cube.move_map.keys())\n",
    "    valid_positions = solved_cube.edge_positions if piece_type == \"edge\" else solved_cube.corner_positions\n",
    "\n",
    "    # Algorithm starts here\n",
    "    distance_table = {}\n",
    "    for start_pos in valid_positions:\n",
    "        for target_pos in valid_positions:\n",
    "            if start_pos == target_pos:\n",
    "                distance_table[(start_pos, target_pos)] = 0\n",
    "                continue\n",
    "\n",
    "            if (target_pos, start_pos) in distance_table: #symmetry optimization\n",
    "                distance_table[(start_pos, target_pos)] = distance_table[(target_pos, start_pos)]\n",
    "                continue\n",
    "\n",
    "            # \"Breadth-First Search\" (BFS) begins\n",
    "            visited = set([start_pos])\n",
    "            queue = deque([(start_pos, 0)])\n",
    "            found_distance = -1\n",
    "\n",
    "            while queue:\n",
    "                current_pos, dist = queue.popleft()\n",
    "                if current_pos == target_pos:\n",
    "                    found_distance = dist\n",
    "                    break\n",
    "                \n",
    "                # Explore all possible moves from current_pos in the table/graph\n",
    "                for move in movement_table[current_pos]:\n",
    "                    next_pos = movement_table[current_pos][move]\n",
    "                    if next_pos not in visited:\n",
    "                        visited.add(next_pos)\n",
    "                        queue.append((next_pos, dist + 1))\n",
    "\n",
    "            distance_table[(start_pos, target_pos)] = found_distance\n",
    "\n",
    "    serializable_table = {}\n",
    "    for pos_pair, dist in distance_table.items(): # Key is position pair\n",
    "        serializable_table[str(pos_pair)] = dist\n",
    "    if piece_type not in filename or \"distance\" not in filename:\n",
    "        raise ValueError(\"Incorrect filename\")\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(serializable_table, f, indent=2)\n",
    "\n",
    "    # Acknowledge successful table creation\n",
    "    print(\"Created the table Successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created the table Successfully\n",
      "Created the table Successfully\n"
     ]
    }
   ],
   "source": [
    "generate_distance_table(\"edge\", \"../Precomputed_Tables/edge_position_distance_table.json\")\n",
    "generate_distance_table(\"corner\", \"../Precomputed_Tables/corner_position_distance_table.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_primary_path_table(filename:str, piece_type:str):\n",
    "    \"\"\"\n",
    "    Builds a minimum-path dictionary from every piece of the given piece_type to every other piece of that type and stores it in the given json file.\n",
    "    Args:\n",
    "        filename: The name of the json file for the table to be stored in\n",
    "        piece_type: `'edge'` or `'corner'`\n",
    "    \"\"\"\n",
    "\n",
    "    # Retrieve the serializable distance table of the corresponding piece type:\n",
    "    if piece_type == 'edge':\n",
    "        filename_1 = \"../Precomputed_Tables/edge_position_distance_table.json\"\n",
    "    else:\n",
    "        filename_1 = \"../Precomputed_Tables/corner_position_distance_table.json\"\n",
    "    try:\n",
    "        with open(filename_1, \"r\") as f:\n",
    "            serializable_table:dict = json.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading file {filename_1}: {e}\")\n",
    "\n",
    "    # Serialize the loaded distance table with the following two structures - \n",
    "    # {init_position(tuple): {distance(int): [final_position(tuple), ...]}}\n",
    "    # {init_position(tuple): {final_position(tuple): distance(int)}}\n",
    "    distance_table_1 = defaultdict(lambda: defaultdict(list))\n",
    "    distance_table_2 = defaultdict(dict)\n",
    "    for pos_pair, distance in serializable_table.items():\n",
    "        pos_pair_tuple = tuple(ast.literal_eval(pos_pair))\n",
    "        init_pos = pos_pair_tuple[0]\n",
    "        final_pos = pos_pair_tuple[1]\n",
    "        distance_table_1[init_pos][distance].append(final_pos)\n",
    "        distance_table_2[init_pos][final_pos] = distance\n",
    "\n",
    "    # Load the position_movement_table created in a previous cell:\n",
    "    try:\n",
    "        filename_2 = \"../Precomputed_Tables/position_movement_table.json\"\n",
    "        with open(filename_2, 'r') as f:\n",
    "            serializable_table:dict = json.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load {filename_2}: {e}\")\n",
    "\n",
    "    # Serialize the loaded movement json table with the structure -\n",
    "    # {position(tuple): {new_position(tuple): [move(str), ...]}}\n",
    "    movement_table = defaultdict(lambda: defaultdict(list))\n",
    "    for move, position_movements in serializable_table.items():\n",
    "        for from_pos_str, to_pos_str in position_movements.items():\n",
    "            from_pos = tuple(ast.literal_eval(from_pos_str))\n",
    "            to_pos = tuple(ast.literal_eval(to_pos_str))\n",
    "            movement_table[from_pos][to_pos].append(move)\n",
    "    \n",
    "    # Get possible distances list:\n",
    "    possible_distances = []\n",
    "    for position, distances in distance_table_1.items():\n",
    "            possible_distances.extend(distances.keys())\n",
    "    possible_distances = sorted(list(set(possible_distances)))\n",
    "    possible_distances.pop(0)\n",
    "    \n",
    "    # Create the data structure to store the final_output (primary_paths) with the structure - \n",
    "    # {path_length(int): {position(tuple): {new_position(tuple): [move_sequence(str), ...]}}}\n",
    "    primary_paths = defaultdict(lambda: defaultdict(lambda: defaultdict(list)))\n",
    " \n",
    "    # Begin building paths:\n",
    "    # Create a fresh Cube object\n",
    "    cube = Cube()\n",
    "    # Build length-zero paths:\n",
    "    if piece_type == \"edge\":\n",
    "        piece_positions = cube.edge_positions\n",
    "    else:\n",
    "        piece_positions = cube.corner_positions\n",
    "    for piece_position in piece_positions:\n",
    "        primary_paths[0][piece_position][piece_position] = ['N']\n",
    "\n",
    "    # Build the rest\n",
    "    for current_distance in possible_distances:\n",
    "        for init_pos, final_positions_for_dists in distance_table_1.items():\n",
    "            for previous_level_final_pos, previous_level_paths in primary_paths[current_distance-1][init_pos].items():\n",
    "                for final_position in final_positions_for_dists[current_distance]:\n",
    "                    if distance_table_2[previous_level_final_pos][final_position] == 1:\n",
    "                        for previous_level_path in previous_level_paths:\n",
    "                            for move in movement_table[previous_level_final_pos][final_position]:\n",
    "                                primary_paths[current_distance][init_pos][final_position].append(previous_level_path+move)\n",
    "    \n",
    "    # Dump the table into the json file\n",
    "    serializable_table = defaultdict(lambda: defaultdict(dict))\n",
    "    for distance, x in primary_paths.items():\n",
    "        for init_position, y in x.items():\n",
    "            for final_position, paths in y.items():\n",
    "                json_paths = \", \".join([path for path in paths])\n",
    "                serializable_table[str(distance)][str(init_position)][str(final_position)] = json_paths\n",
    "    if piece_type not in filename or \"path\" not in filename:\n",
    "        raise ValueError(\"Incorrect filename\")\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(serializable_table, f, indent=2)\n",
    "\n",
    "    # Acknowledge successful table creation\n",
    "    print(\"Created the table Successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created the table Successfully\n",
      "Created the table Successfully\n"
     ]
    }
   ],
   "source": [
    "generate_primary_path_table(\"../Precomputed_Tables/edge_primary_path_table.json\", \"edge\")\n",
    "generate_primary_path_table(\"../Precomputed_Tables/corner_primary_path_table.json\", \"corner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
